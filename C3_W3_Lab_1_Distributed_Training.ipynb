{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajgquional/Coursera_ML-Modeling-Pipelines-in-Prod/blob/main/C3_W3_Lab_1_Distributed_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Ungraded lab: Distributed Strategies with TF and Keras\n",
        "------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yL0-KcLPwtk"
      },
      "source": [
        "Welcome! During this ungraded lab you are going to perform a distributed training strategy using TensorFlow and Keras, specifically the [`tf.distribute.MultiWorkerMirroredStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy).\n",
        "\n",
        "With the help of this strategy, a Keras model that was designed to run on single-worker can seamlessly work on multiple workers with minimal code change. In particular you will:\n",
        "\n",
        "\n",
        "1. Perform training with a single worker.\n",
        "2. Understand the requirements for a multi-worker setup (`tf_config` variable) and using context managers for implementing distributed strategies.\n",
        "3. Use magic commands to simulate different machines.\n",
        "4. Perform a multi-worker training strategy.\n",
        "\n",
        "This notebook is based on the official [Multi-worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) notebook, which covers some additional topics in case you want a deeper dive into this topic.\n",
        "\n",
        "[Distributed Training with TensorFlow](https://www.tensorflow.org/guide/distributed_training) guide is also available for an overview of the distribution strategies TensorFlow supports for those interested in a deeper understanding of `tf.distribute.Strategy` APIs.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, some necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bnYxvfLD-LW-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Log additional outputs from TF's C++ backend\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0EY91y3mxy"
      },
      "source": [
        "Before importing TensorFlow, make a few changes to the environment.\n",
        "\n",
        "- Disable all GPUs. This prevents errors caused by the workers all trying to use the same GPU. **For a real application each worker would be on a different machine.**\n",
        "\n",
        "\n",
        "- Add the current directory to python's path so modules in this directory can be imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "685pbYEY3jGC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Disable GPUs\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "# Add current directory to path\n",
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd4L9Ii77SS8"
      },
      "source": [
        "The previous step is important since this notebook relies on writting files using the magic command `%%writefile` and then importing them as modules.\n",
        "\n",
        "Now that the environment configuration is ready, import TensorFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vHNvttzV43sA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ignore warnings\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2jpf6Sx50i"
      },
      "source": [
        "### Dataset and model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLW6D2TzvC-4"
      },
      "source": [
        "Next create an `mnist.py` file with a simple model and dataset setup. This python file will be used by the worker-processes in this tutorial.\n",
        "\n",
        "The name of this file derives from the dataset you will be using which is called [mnist](https://keras.io/api/datasets/mnist/) and consists of 60,000 28x28 grayscale images of the first 10 digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dma_wUAxZqo2",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc42374-7d78-4775-abef-1a8380f4d2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mnist.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mnist.py\n",
        "\n",
        "# import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  # Load the data\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # Normalize pixel values for x_train and cast to float32\n",
        "  x_train = x_train / np.float32(255)\n",
        "  # Cast y_train to int64\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  # Define repeated and shuffled dataset\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
        "  return train_dataset\n",
        "\n",
        "\n",
        "def build_and_compile_cnn_model():\n",
        "  # Define simple CNN model using Keras Sequential\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbDEKpGowcyT"
      },
      "source": [
        "Check that the file was succesfully created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IxsnfpVurQ1g",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50eb9c67-2600-4264-b377-1320256a2061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist.py\n"
          ]
        }
      ],
      "source": [
        "!ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UL3kisMO90X"
      },
      "source": [
        "Import the mnist module you just created and try training the model for a small number of epochs to observe the results of a single worker to make sure everything works correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6Qe6iAf5O8iJ",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd02544-7c2c-4fc7-dcd9-2486fa064b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.1256 - loss: 2.2866\n",
            "Epoch 2/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.3038 - loss: 2.2132\n",
            "Epoch 3/3\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.5335 - loss: 2.1219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ca15c81fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Import your mnist model\n",
        "import mnist\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Load the dataset\n",
        "single_worker_dataset = mnist.mnist_dataset(batch_size)\n",
        "\n",
        "# Load compiled CNN model\n",
        "single_worker_model = mnist.build_and_compile_cnn_model()\n",
        "\n",
        "# As training progresses, the loss should drop and the accuracy should increase.\n",
        "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpLPWFJh1CAK"
      },
      "source": [
        "Everything is working as expected!\n",
        "\n",
        "Now you will see how multiple workers can be used as a distributed strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmgZwwymxqt5"
      },
      "source": [
        "## Multi-worker Configuration\n",
        "\n",
        "Now let's enter the world of multi-worker training. In TensorFlow, the `TF_CONFIG` environment variable is required for training on multiple machines, each of which possibly has a different role. `TF_CONFIG` is a JSON string used to specify the cluster configuration on each worker that is part of the cluster.\n",
        "\n",
        "There are two components of `TF_CONFIG`: `cluster` and `task`.\n",
        "\n",
        "Let's dive into how they are used:\n",
        "\n",
        "`cluster`:\n",
        "- **It is the same for all workers** and provides information about the training cluster, which is a dict consisting of different types of jobs such as `worker`.\n",
        "\n",
        "- In multi-worker training with `MultiWorkerMirroredStrategy`, there is usually one `worker` that takes on a little more responsibility like saving checkpoint and writing summary file for TensorBoard in addition to what a regular `worker` does.\n",
        "-Such a worker is referred to as the `chief` worker, and it is customary that the `worker` with `index` 0 is appointed as the chief `worker` (in fact this is how `tf.distribute.Strategy` is implemented).\n",
        "\n",
        "`task`:\n",
        "- Provides information of the current task and is different on each worker. It specifies the `type` and `index` of that worker.\n",
        "\n",
        "Here is an example configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XK1eTYvSZiX7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgwJbPKZkJL"
      },
      "source": [
        "Here is the same `TF_CONFIG` serialized as a JSON string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yY-T0YDQZjbu",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9161987-6f40-4f7f-a70e-67b401df3c73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:23456\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFpxrcsZ2xG"
      },
      "source": [
        "### Explaining the TF_CONFIG example\n",
        "\n",
        "In this example you set a `TF_CONFIG` with 2 workers on `localhost`. In practice, users would create multiple workers on external IP addresses/ports, and set `TF_CONFIG` on each worker appropriately.\n",
        "\n",
        "Since you set the task `type` to `\"worker\"` and the task `index` to `0`, **this machine is the first worker and will be appointed as the chief worker**.\n",
        "\n",
        "Note that other machines will need to have the `TF_CONFIG` environment variable set as well, and it should have the same `cluster` dict, but different task `type` or task `index` depending on what the roles of those machines are. For instance, for the second worker you would set `tf_config['task']['index']=1`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f83FVYqDX3aX"
      },
      "source": [
        "### Quick Note on Environment variables and subprocesses in notebooks\n",
        "\n",
        "Above, `tf_config` is just a local variable in python. To actually use it to configure training, this dictionary needs to be serialized as JSON, and placed in the `TF_CONFIG` environment variable.\n",
        "\n",
        "In the next section, you'll spawn new subprocesses for each worker using the `%%bash` magic command. Subprocesses inherit environment variables from their parent, so they can access `TF_CONFIG`.\n",
        "\n",
        "You would never really launch your jobs this way (as subprocesses of an interactive Python runtime), but it's how you will do it for the purposes of this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNtHfuxCGVy"
      },
      "source": [
        "## Choose the right strategy\n",
        "\n",
        "In TensorFlow there are two main forms of distributed training:\n",
        "\n",
        "* Synchronous training, where the steps of training are synced across the workers and replicas, and\n",
        "* Asynchronous training, where the training steps are not strictly synced.\n",
        "\n",
        "`MultiWorkerMirroredStrategy`, which is the recommended strategy for synchronous multi-worker training, is the one you will be using.\n",
        "\n",
        "To train the model, use an instance of `tf.distribute.MultiWorkerMirroredStrategy`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1uFSHCJXMrQ-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0iv7SyyAohc"
      },
      "source": [
        "`MultiWorkerMirroredStrategy` creates copies of all variables in the model's layers on each device across all workers.  It uses `CollectiveOps`, a TensorFlow op for collective communication, to aggregate gradients and keep the variables in sync.  The [official TF distributed training guide](https://www.tensorflow.org/guide/distributed_training) has more details about this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H47DDcOgfzm7"
      },
      "source": [
        "### Implement Distributed Training via Context Managers\n",
        "\n",
        "To distribute the training to multiple-workers all you need to do is to enclose the model building and `model.compile()` call inside `strategy.scope()`.\n",
        "\n",
        "The distribution strategy's scope dictates how and where the variables are created, and in the case of `MultiWorkerMirroredStrategy`, the variables created are `MirroredVariable`s, and they are replicated on each of the workers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wo6b9wX65glL",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Implementing distributed strategy via a context manager\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist.build_and_compile_cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYpmIxO6Jck"
      },
      "source": [
        "Note: `TF_CONFIG` is parsed and TensorFlow's GRPC servers are started at the time `MultiWorkerMirroredStrategy()` is called, so the `TF_CONFIG` environment variable must be set before a `tf.distribute.Strategy` instance is created.\n",
        "\n",
        "**Since `TF_CONFIG` is not set yet the above strategy is effectively single-worker training**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxzYhF0dL6qQ"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Create training script\n",
        "\n",
        "To actually run with `MultiWorkerMirroredStrategy` you'll need to run worker processes and pass a `TF_CONFIG` to them.\n",
        "\n",
        "Like the `mnist.py` file written earlier, here is the `main.py` that each of the workers will run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BcsuBYrpgnlS",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbafc421-9c3e-4d33-ecc1-ca1e6528ed08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "import mnist # Your module\n",
        "\n",
        "# Define batch size\n",
        "per_worker_batch_size = 64\n",
        "\n",
        "# Get TF_CONFIG from the env variables and save it as JSON\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "\n",
        "# Infer number of workers from tf_config\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "# Define strategy\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "# Define global batch size\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "# Load dataset\n",
        "multi_worker_dataset = mnist.mnist_dataset(global_batch_size)\n",
        "\n",
        "# Create and compile model following the distributed strategy\n",
        "with strategy.scope():\n",
        "    multi_worker_model = mnist.build_and_compile_cnn_model()\n",
        "\n",
        "# Train the model\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aom9xelvJQ_6"
      },
      "source": [
        "In the code snippet above note that the `global_batch_size`, which gets passed to `Dataset.batch`, is set to `per_worker_batch_size * num_workers`. This ensures that each worker processes batches of `per_worker_batch_size` examples regardless of the number of workers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHLhOii67Saa"
      },
      "source": [
        "The current directory should now contain both Python files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bi6x05Sr60O9",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cea187-3d08-4b09-8c13-49fef9948a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.py  mnist.py\n"
          ]
        }
      ],
      "source": [
        "!ls *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEEStPS6vR_"
      },
      "source": [
        "### Set TF_CONFIG environment variable\n",
        "\n",
        "Now json-serialize the `TF_CONFIG` and add it to the environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9uu3g7vV7Bbt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Set TF_CONFIG env variable\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WDqwMPNneON"
      },
      "source": [
        "And terminate all background processes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "txMXaq8d8N_S",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae207ac9-4daf-4d7f-eacb-39602fac8337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All background processes were killed.\n"
          ]
        }
      ],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl-gazCifc07"
      },
      "source": [
        "Before launching the first worker you can check that port `12345` is free at the time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "JP0q9jkTfc09"
      },
      "outputs": [],
      "source": [
        "# This should not print anything at the moment\n",
        "!lsof -i :12345"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsY3dQLK7jdf"
      },
      "source": [
        "### Launch the first worker\n",
        "\n",
        "Now, you can launch a worker process that will run the `main.py` and use the `TF_CONFIG`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qnSma_Ck7r-r",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChyazqS7v0P"
      },
      "source": [
        "There are a few things to note about the above command:\n",
        "\n",
        "1. It uses the `%%bash` which is a [notebook \"magic\"](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to run some bash commands.\n",
        "2. It uses the `--bg` flag to run the `bash` process in the background, because this worker will not terminate. It waits for all the workers before it starts.\n",
        "\n",
        "The backgrounded worker process won't print an output to this notebook, so the `&>` redirects its output to a file, so you can see what happened.\n",
        "\n",
        "So, wait a few seconds for the process to start up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hm2yrULE9281",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Wait for logs to be written to the file\n",
        "time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVelN5Jfc1n"
      },
      "source": [
        "Now you can check again at the status of port `12345`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "rFM7oe9Sfc1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cb488a-57f1-429e-cdb0-32c47de4c22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 463 root    6u  IPv4  31210      0t0  TCP *:12345 (LISTEN)\n",
            "python3 463 root   13u  IPv4  31217      0t0  TCP localhost:46102->localhost:12345 (ESTABLISHED)\n",
            "python3 463 root   14u  IPv4  31218      0t0  TCP localhost:12345->localhost:46102 (ESTABLISHED)\n"
          ]
        }
      ],
      "source": [
        "!lsof -i :12345"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFPoNxg_9_Mx"
      },
      "source": [
        "Now look what's been output to the worker's logfile so far using the `cat` command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vZEOuVgQ9-hn",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421ef62d-a287-4494-bad4-af79d80c4a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-08 19:09:24.170607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744139364.200356     463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744139364.210500     463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-08 19:09:24.245253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-08 19:09:29.806339: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2025-04-08 19:09:29.818824: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:447] Initializing CoordinationService\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1744139369.819848     463 grpc_server_lib.cc:464] Started server with target: grpc://localhost:12345\n",
            "2025-04-08 19:09:29.844648: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:700] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 15502714764654917105\n",
            "2025-04-08 19:09:29.844728: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:653] Waiting for 1/2 tasks to connect.\n",
            "2025-04-08 19:09:29.844742: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:656] Example stragglers:\n",
            "/job:worker/replica:0/task:1\n",
            "I0000 00:00:1744139369.844930     463 coordination_service_agent.cc:340] Coordination agent has successfully connected.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqZhVF7L_KOy"
      },
      "source": [
        "The last line of the log file should say: `Started server with target: grpc://localhost:12345`. The first worker is now ready, and is waiting for all the other worker(s) to be ready to proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8vPNNA_l4a"
      },
      "source": [
        "### Launch the second worker\n",
        "\n",
        "Now update the `tf_config` for the second worker's process to pick up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lAiYkkPu_Jqd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AshGVO0_x0w"
      },
      "source": [
        "Now launch the second worker. This will start the training since all the workers are active (so there's no need to background this process):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_ESVtyQ9_xjx",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351c2952-608b-4ff1-dac6-f5112c9083a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4FA2O2AuAn"
      },
      "source": [
        "Now if you recheck the logs written by the first worker you'll see that it participated in training that model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rc6hw3yTBKXX",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595e9f3b-73a4-45e4-8814-c8fa422735c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-08 19:09:24.170607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744139364.200356     463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744139364.210500     463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-08 19:09:24.245253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-08 19:09:29.806339: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2025-04-08 19:09:29.818824: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:447] Initializing CoordinationService\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1744139369.819848     463 grpc_server_lib.cc:464] Started server with target: grpc://localhost:12345\n",
            "2025-04-08 19:09:29.844648: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:700] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 15502714764654917105\n",
            "2025-04-08 19:09:29.844728: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:653] Waiting for 1/2 tasks to connect.\n",
            "2025-04-08 19:09:29.844742: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:656] Example stragglers:\n",
            "/job:worker/replica:0/task:1\n",
            "I0000 00:00:1744139369.844930     463 coordination_service_agent.cc:340] Coordination agent has successfully connected.\n",
            "2025-04-08 19:09:38.614695: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:700] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 5674279686646862952\n",
            "2025-04-08 19:09:38.614766: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:653] Waiting for 0/2 tasks to connect.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "2025-04-08 19:09:40.383780: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/main.py\", line 31, in <module>\n",
            "    multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\", line 108, in convert_to_eager_tensor\n",
            "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: Attempt to convert a value (PerReplica:{\n",
            "  0: <tf.Tensor: shape=(64, 28, 28), dtype=float32, numpy=\n",
            "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]],\n",
            "\n",
            "       [[0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.],\n",
            "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>\n",
            "}) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL79ak5PMzEg"
      },
      "source": [
        "Unsurprisingly this ran _slower_ than the the test run at the beginning of this tutorial. **Running multiple workers on a single machine only adds overhead**. The goal here was not to improve the training time, but only to give an example of multi-worker training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xckY28bOV_p8"
      },
      "source": [
        "-----------------------------\n",
        "**Congratulations on finishing this ungraded lab!** Now you should have a clearer understanding of how to implement distributed strategies with Tensorflow and Keras.\n",
        "\n",
        "Although this tutorial didn't show the true power of a distributed strategy since this will require multiple machines operating under the same network, you now know how this process looks like at a high level.\n",
        "\n",
        "In practice and especially with very big models, distributed strategies are commonly used as they provide a way of better managing resources to perform time-consuming tasks, such as training in a fraction of the time that it will take without the strategy.\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}